import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Button } from './ui/button';
import { Input } from './ui/input';
import { Phone, Send, Volume2, Copy, Check, PhoneOff, ArrowLeft, Keyboard } from 'lucide-react';
import { ResizableHandle, ResizablePanel, ResizablePanelGroup } from "./ui/resizable";
import { isMobileDevice } from '@/hooks/use-media-query';
import { Word } from '@/lib/types/words';
import { globalCache, Page,pages } from './app-router';
import { Switch } from './ui/switch'
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from "./ui/tooltip";
import {  AudioPlayer, audioToWav,  MicrophoneSoundDetector } from '@/app/utils/audio';
import { ResultReason, SpeechSynthesizer } from 'microsoft-cognitiveservices-speech-sdk';
import * as speechsdk from 'microsoft-cognitiveservices-speech-sdk';
import { chatPromptTemplate, englishGrammaticalTeacherTemplate } from '@/app/utils/promptTemplates';
import { Message } from '@/lib/types/message';


let globalRecognizer: speechsdk.SpeechRecognizer | null = null;
let globalSpeechSynthesizer: speechsdk.SpeechSynthesizer | null = null;
let tokenExpirationTime: number = 0;




interface TodayDialogProps {
  navigateTo: (page: Page) => void;
}

const USER_ROLE = "user"
const MODEL_ROLE = "model"

const TodayDialogComponent: React.FC<TodayDialogProps> = ({ navigateTo }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const chatContainerRef = useRef<HTMLDivElement>(null);

  const [isLeftPanelCollapsed, setIsLeftPanelCollapsed] = useState(isMobileDevice());
  const [words, setWords] = useState<Word[]>([])
  // const [currentAiMessage, setCurrentAiMessage] = useState('');
  const [textToSpeechEnabled, setTextToSpeechEnabled] = useState(true);
  // const [isWaiting, setIsWaiting] = useState(false);
  const [audioCache, setAudioCache] = useState<{[key: string]: string}>({});
  const [playingAudio, setPlayingAudio] = useState<string | null>(null);
  const [copiedText, setCopiedText] = useState<string | null>(null);
  const [currentUserMessageIndex, setCurrentUserMessageIndex] = useState<number | 1>(1);
  const [currentModelMessageIndex, setCurrentModelMessageIndex] = useState<number | 0>(0);
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null);
  const [sourceNode, setSourceNode] = useState<AudioBufferSourceNode | null>(null);
  const [isCallActive, setIsCallActive] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [shouldSend, setShouldSend] = useState(false);
  const [isWaitingAiChat, setIsWaitingAiChat] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [showInput, setShowInput] = useState(false);
  const [isTransitioning, setIsTransitioning] = useState(false);
  
   // æ–°å¢ï¼šä½¿ç”¨ useRef æ¥è·Ÿè¸ªæœ€æ–°çš„ messages
   const messagesRef = useRef<Message[]>([]);

   // æ›´æ–° messagesRef å½“ messages æ”¹å˜æ—¶
   useEffect(() => {
     messagesRef.current = messages;
   }, [messages]);

  const isMounted = useRef(true);
  useEffect(() => {
    return () => {
      isMounted.current = false;
    };
  }, []);

  useEffect(() => {
    if (isListening) {
      setIsTransitioning(false)
    } 
  }, [isListening])



  useEffect(() => {
    // åˆå§‹åŒ– globalRecognizer
    async function initializeGlobalRecognizer() {
      try {
        const speechToken = await getSpeechToken();
        if (speechToken?.token && speechToken?.region) {
          globalRecognizer = initializeRecognizer(speechToken.token, speechToken.region);
          tokenExpirationTime = Date.now() + 9 * 60 * 1000;
          console.log('è¯­éŸ³è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ');
        } else {
          throw new Error('æ— æ³•è·å–è¯­éŸ³ä»¤ç‰Œ');
        }
      } catch (error) {
        console.error('åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨æ—¶å‡ºé”™:', error);
      }
    }
    initializeGlobalRecognizer();

    
    // è¿”å›ä¸€ä¸ªæ¸…ç†å‡½æ•°ï¼Œå®ƒä¼šåœ¨ç»„ä»¶å¸è½½æ—¶æ‰§è¡Œ
    return () => {
      if (globalRecognizer) {
        console.log('Closing speech recognizer...');
        globalRecognizer.close();
        globalRecognizer = null;
      }
      if (globalSpeechSynthesizer) {
        console.log('Closing speech synthesizer...');
        globalSpeechSynthesizer.close();
        globalSpeechSynthesizer = null;
      }
    };
  }, []); // ç©ºä¾èµ–æ•°ç»„æ„å‘³ç€è¿™ä¸ªæ•ˆæœåªåœ¨ç»„ä»¶æŒ‚è½½å’Œå¸è½½æ—¶è¿è¡Œ


  // åœ¨æ¶ˆæ¯æ›´æ–°æ—¶æ»šåŠ¨åˆ°é¡¶éƒ¨
  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight  ;
    }
  }, [messages]); // å‡è®¾ messages æ˜¯å­˜å‚¨å¯¹è¯æ¶ˆæ¯çš„çŠ¶æ€


  useEffect(() => {
    
    fetch('/api/daily-words')
    .then(response => response.json())
    .then((data: Word[]) => {
      setWords(data);
      setMessages([{ 
        role: 'model', 
        parts: [{ 
          text: `ä½ å¥½å‘€ï¼æˆ‘æ˜¯ä½ çš„ä»Šå¤©çš„è‹±è¯­è€å¸ˆï¼ä»Šå¤©å’±ä»¬å­¦äº†ä»¥ä¸‹å•è¯ï¼Œæœ‰12ä¸ªå•è¯è¯¶ï¼é‚£ä½ æƒ³ä»å“ªä¸ªå•è¯å¼€å§‹èŠèµ·å‘¢ï¼Ÿ`
        }] 
      }]);
    })
    .catch(error => {
      console.error('è·å–å•è¯æ—¶å‡ºé”™:', error)
    })
  }, []);

  useEffect(() => {

    // å½“å¯¹è¯ä¸­çš„modelçš„messageçš„textä¸­åŒ…å«wordsä¸­çš„ä¸€ä¸ªï¼Œåˆ™å°†å•è¯çš„hitCount+1
    messages.forEach(message => {
      if (message.role === 'model') {
        words.forEach(word => {
          if (message.parts[0].text.includes(word.english)) {
            setWords(prevWords => prevWords.map(w => w.english === word.english ? { ...w, hitCount: (w.hitCount || 0) + 1 } : w));
          }
        });
      }
    });
  }, [messages]);

  useEffect(() => {
    if (messages.length > 1 && shouldSend ) {
      messageSend(messages);
    }
  }, [shouldSend]);

  useEffect(() => {
    setIsLeftPanelCollapsed(isMobileDevice());
  }, []);


  const getSpeechToken = async () => {
    try {
        const response = await fetch(`/api/speech-token?timestamp=${new Date().getTime()}`, {
            next: {
              revalidate: 600, // 10 min
            },
            cache: 'no-store',
            headers: {
              'Cache-Control': 'no-cache'
            }
          });
        if (response.ok) {
            const data = await response.json();
            return data;
        } else {
            console.error('è·å–è¯­éŸ³ä»¤ç‰Œå¤±è´¥');
            return null;
        }
    } catch (error) {
        console.error('è·å–è¯­éŸ³ä»¤ç‰Œæ—¶å‡ºé”™:', error);
        return null;
    }
};



  // æ–°å¢ï¼šåˆå§‹åŒ– recognizer çš„å‡½æ•°
  function initializeRecognizer(token: string, region: string): speechsdk.SpeechRecognizer {
    const speechConfig = speechsdk.SpeechConfig.fromAuthorizationToken(token, region);
    speechConfig.speechRecognitionLanguage = 'zh-CN';
    
    const audioConfig = speechsdk.AudioConfig.fromDefaultMicrophoneInput();
    return new speechsdk.SpeechRecognizer(speechConfig, audioConfig);
  }

  // æ–°å¢ä¸€ä¸ªÂ· speechSynthesizer å‡½æ•°
  function initializeSpeechSynthesizer(token: string, region: string): speechsdk.SpeechSynthesizer {
    const speechConfig = speechsdk.SpeechConfig.fromAuthorizationToken(token, region);
    // zh-CN-XiaoyuMultilingualNeural
    // zh-CN-XiaoxiaoMultilingualNeural
    speechConfig.speechSynthesisVoiceName = 'zh-CN-XiaochenMultilingualNeural'
    const audioConfig = speechsdk.AudioConfig.fromDefaultSpeakerOutput();
    

    return new SpeechSynthesizer(speechConfig, audioConfig);
  }


  async function refreshTokenIfNeeded() {
    const currentTime = Date.now();
    if (currentTime >= tokenExpirationTime) {
      const speechToken = await getSpeechToken();
      if (speechToken?.token && speechToken?.region) {
        if (globalRecognizer) {
          globalRecognizer.authorizationToken = speechToken.token;
        }
        // è®¾ç½®æ–°çš„è¿‡æœŸæ—¶é—´ï¼ˆ9åˆ†é’Ÿåï¼Œç•™å‡ºä¸€åˆ†é’Ÿçš„ç¼“å†²æ—¶é—´ï¼‰
        tokenExpirationTime = currentTime + 9 * 60 * 1000;
        return { token: speechToken.token, region: speechToken.region };
      } else {
        throw new Error('æ— æ³•è·å–æ–°çš„è¯­éŸ³ä»¤ç‰Œ');
      }
    }
    return null; // ä»¤ç‰Œä»ç„¶æœ‰æ•ˆ
  }

  async function tts (message :string,messageIndex:number) {

    const emojiRegex = /[\uD800-\uDBFF][\uDC00-\uDFFF]|[\u2600-\u27BF]|[\uE000-\uF8FF]|\uD83C[\uDC00-\uDFFF]|\uD83D[\uDC00-\uDFFF]|[\u2700-\u27BF]/g;
    const realMessage = message.replace(emojiRegex,"")

    // å¦‚æœæœ‰ç¼“å­˜ï¼Œåˆ™ç›´æ¥æ’­æ”¾
    if (audioCache[realMessage]) {
      const audio = new Audio(audioCache[realMessage]);
      audio.play();
      return
    }

    if (!textToSpeechEnabled) {
      return
    }
    const refreshedToken = await refreshTokenIfNeeded();
    if (refreshedToken) {
      if (globalSpeechSynthesizer) {
        globalSpeechSynthesizer.close();
      }
      globalSpeechSynthesizer = initializeSpeechSynthesizer(refreshedToken.token, refreshedToken.region)
    } else if (!globalSpeechSynthesizer) {
      // å¦‚æœrecognizerä¸å­˜åœ¨ï¼Œä½¿ç”¨å½“å‰ä»¤ç‰Œåˆå§‹åŒ–
      const speechToken = await getSpeechToken();
      if (speechToken?.token && speechToken?.region) {
        globalSpeechSynthesizer = initializeSpeechSynthesizer(speechToken.token, speechToken.region);
        tokenExpirationTime = Date.now() + 9 * 60 * 1000;
      } else {
        throw new Error('æ— æ³•è·å–è¯­éŸ³ä»¤ç‰Œ');
      }
    }

    globalSpeechSynthesizer.speakTextAsync(realMessage,
      result => {
        if (result) {
          if (result.reason === ResultReason.SynthesizingAudioCompleted) {
            // console.log('SynthesizingAudioCompleted')
          } else if (result.reason === ResultReason.Canceled) {
            console.error(`Speech synthesis canceled: ${result.errorDetails}`);
          }
          globalSpeechSynthesizer?.close();
          globalSpeechSynthesizer = null;
          // ä¿å­˜éŸ³é¢‘cache
          setAudioCache(prev => {
            const newCache = { [realMessage]: URL.createObjectURL(new Blob([result.audioData], { type: 'audio/mpeg' })), ...prev };
            const cacheEntries = Object.entries(newCache);
            if (cacheEntries.length > 10) {
              const [oldestKey] = cacheEntries[10];
              const { [oldestKey]: _, ...rest } = newCache;
              return rest;
            }
            return newCache;
          });
      }
      },error => {
        console.log(error);
        globalSpeechSynthesizer?.close();
      }
    )
   
  }

  async function sttFromMic() {
    setIsTransitioning(true)
    setIsRecording(true)
    setIsListening(true)
    try {
      const refreshedToken = await refreshTokenIfNeeded();
      
      if (refreshedToken) {
        // å¦‚æœä»¤ç‰Œè¢«åˆ·æ–°ï¼Œé‡æ–°åˆå§‹åŒ–recognizer
        if (globalRecognizer) {
          globalRecognizer.close();
        }
        globalRecognizer = initializeRecognizer(refreshedToken.token, refreshedToken.region);
      } else if (!globalRecognizer) {
        // å¦‚æœrecognizerä¸å­˜åœ¨ï¼Œä½¿ç”¨å½“å‰ä»¤ç‰Œåˆå§‹åŒ–
        const speechToken = await getSpeechToken();
        if (speechToken?.token && speechToken?.region) {
          globalRecognizer = initializeRecognizer(speechToken.token, speechToken.region);
          tokenExpirationTime = Date.now() + 9 * 60 * 1000;
        } else {
          throw new Error('æ— æ³•è·å–è¯­éŸ³ä»¤ç‰Œ');
        }
      }

      if (globalRecognizer) {
        setupRecognizerCallbacks();
        globalRecognizer.startContinuousRecognitionAsync();
      }
    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«æ—¶å‡ºé”™:', error);
      setIsListening(false);
    } 
  }


  
  function setupRecognizerCallbacks() {
    if (globalRecognizer) {

      globalRecognizer.sessionStarted = async (s,e) => {
      }

  


      globalRecognizer.recognizing = async (s, e) => {
        
        const currentMessages = messagesRef.current;
        const lastUserMessageIndex = currentMessages.findLastIndex(m => m.role === USER_ROLE);
        if (lastUserMessageIndex !== -1 && (currentMessages.length-1) == lastUserMessageIndex) {
          // æ›´æ–°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
          updateMessage(lastUserMessageIndex, e.result.text, 0);
        } else {
          // å¦‚æœæ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯ï¼Œæ·»åŠ æ–°æ¶ˆæ¯
          await addMessage(e.result.text, 0, USER_ROLE);
        }
        
      };

      globalRecognizer.recognized = async (s, e) => {
        if (!e.result.text || !e.result.text.trim()) {
          return
        }
        // ç«‹å³æ›´æ–°è¾“å…¥
        // await addMessage(e.result.text, 0,USER_ROLE)
        setShouldSend(true)
      };

      globalRecognizer.canceled = (s, e) => {
        console.log(`canceled reason=${e.reason}`);
        if (e.reason == speechsdk.CancellationReason.Error) {
          console.log(`"CANCELED: ErrorCode=${e.errorCode}`);
          console.log(`"CANCELED: ErrorDetails=${e.errorDetails}`);
          console.log("CANCELED: Did you set the speech resource key and region values?");
        }
        setIsListening(false);
        setIsRecording(false)
      };

      globalRecognizer.sessionStopped = (s, e) => {
        console.log("Session stopped event");
        setIsListening(false);
        setIsRecording(false)
        globalRecognizer?.stopContinuousRecognitionAsync()
      };
    }
  }



  const messagesPostToAi = async (messages: Message[],systemPrompt:string): Promise<string> => {


    try {
      const response = await fetch('/api/openai-chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ messages: messages,systemPrompt:systemPrompt }),
      });

      if (!response.ok) {
        throw new Error('API è¯·æ±‚å¤±è´¥');
      }

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let fullMessage = '';
      // æ¥æ”¶æ•°æ®
      while (true) {
        const { done, value } = await reader?.read() ?? { done: true, value: undefined };
        if (done) {
          break;
        }
        fullMessage += decoder.decode(value, { stream: true });
      }

      return fullMessage
    } catch (error) {
      console.error('å‘é€æ¶ˆæ¯æ—¶å‡ºé”™:', error);
      // addMessage('æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚',0,MODEL_ROLE);
    } 
  return ''
}


  const messageSend = async (messages: Message[]) => {
  
    // å‘é€æ¶ˆæ¯åˆ°AI
    const startTime = Date.now();
    setIsWaitingAiChat(true)
    
    let initWords = JSON.parse(JSON.stringify(words.map(word => {
      return {
        word: word.english,
        mentionedTimes: word.hitCount
      }
    })))
    // clone messages
    let realMessages = JSON.parse(JSON.stringify(messages));
    // å°†ç¬¬ä¸€æ¡çš„messageçš„textæ·»åŠ ä¸ŠlearnSituations
    realMessages[0].parts[0].text += ` learnSituations:`+JSON.stringify(initWords)
    
    const fullMessage = await messagesPostToAi(realMessages,chatPromptTemplate())
    // const picketMessage = await messagesPostToAi([realMessages[realMessages.length-1]],englishGrammaticalTeacherTemplate())
    // console.log("picketMessage:{}",picketMessage)
    setIsWaitingAiChat(false)
    const responseTime = Date.now() - startTime
    setShouldSend(false);

    // å¼€å§‹æ’­æ”¾éŸ³é¢‘
    if (textToSpeechEnabled) {
      tts(fullMessage, messages.length - 1)
    }

    // å®ç°æ‰“å­—æœºæ•ˆæœ
    await typeWriter(fullMessage, responseTime)
    }

  // å®ç°æ‰“å­—æœºæ•ˆæœ
  const typeWriter = async (fullMessage: string, responseTime: number) => {

    const firstMessageIndex = await addMessage(fullMessage.substring(0, 1), responseTime,MODEL_ROLE)
    if (firstMessageIndex === -1) {
      return
    }
    
    for (let i = 1; i < fullMessage.length; i++) {
      // æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡ç‚¹ç¬¦å·
      updateMessage(firstMessageIndex,fullMessage.substring(0, i+1), responseTime)
      if (['ï¼Œ', 'ã€‚', 'ï¼Ÿ', 'ï¼'].includes(fullMessage[i])) {
        await new Promise(resolve => setTimeout(resolve, 150));
      } else {
        await new Promise(resolve => setTimeout(resolve, 50));
      }
    }

    updateMessage(firstMessageIndex,fullMessage, responseTime)
  }

  const addMessage = (text: string, requestTime: number,role: string,show:boolean = true): Promise<number> => {
    if (!text || !text.trim()) {
      return Promise.resolve(-1)
    }


    return new Promise((resolve) => {
      setMessages(prevMessages => {
        const newRole = role
        const updatedMessages = [...prevMessages, { role: newRole, parts: [{ text }], requestTime }];
        if (role == USER_ROLE) {
          setCurrentUserMessageIndex(updateMessage.length-1)
        } else{
          setCurrentModelMessageIndex(updateMessage.length-1)
        }
        messagesRef.current = updatedMessages;
        resolve(updatedMessages.length - 1);
        return updatedMessages;
      });
    });
  };

  const updateMessage = (index: number, text: string, requestTime: number) => {
    setMessages(prevMessages => {
      const updatedMessages = [...prevMessages];
      updatedMessages[index].parts[0].text = text;
      updatedMessages[index].requestTime = requestTime;
      return updatedMessages;
    });
  };

    
  const handleClickSend = async () => {
    if (input && input.trim()) {
      await addMessage(input,0,USER_ROLE)
      setShouldSend(true)
      setInput('')
    }
  };



  const handleCopy = (text: string) => {
    navigator.clipboard.writeText(text).then(() => {
      setCopiedText(text);
      setTimeout(() => setCopiedText(null), 1000);
    });
  };

  const leftPanelContent = (
    <div className="h-auto p-4 bg-gray-100">
      <h2 className="text-lg font-bold mb-4">ä»Šæ—¥å•è¯</h2>
      {!isLeftPanelCollapsed && words.map((word, index) => (
        <div key={index} className="mb-2 sm:text-sm text-xs">
          <span className="font-bold text-gray-800">{word.english}</span> - <span className="text-gray-600">{word.chinese}</span>
        </div>
      ))}
    </div>
  );

  const scrollToBottom = useCallback(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight;
    }
  }, []);

  useEffect(() => {
    scrollToBottom();
    
    const chatContainer = chatContainerRef.current;
    if (chatContainer) {
      const observer = new MutationObserver(scrollToBottom);
      observer.observe(chatContainer, { childList: true, subtree: true });
      
      return () => observer.disconnect();
    }
  }, [scrollToBottom]);

  const stopAudioPlayback = () => {
    if (sourceNode) {
      sourceNode.stop();
      setSourceNode(null);
    }
    if (audioContext) {
      audioContext.close();
      setAudioContext(null);
    }
    setPlayingAudio(null);
  };



  const startRecording = async () => {
    // setIsCallActive(true);
    sttFromMic()
  };

  const stopRecording = () => {    
    globalRecognizer?.stopContinuousRecognitionAsync();
  };



  const handleCallStart = () => {
    startRecording();
  };

  const handleCallEnd = () => {
    setIsRecording(false);
    stopRecording();
  };

  const handleRecordSwitch = () => {
    if (!isRecording) {
      startRecording()
    } else {
      stopRecording();
    }
  };


  return (
    <ResizablePanelGroup direction="horizontal" className="relative">
      <ResizablePanel
        defaultSize={25}
        collapsible={isLeftPanelCollapsed}
        collapsedSize={5}
        minSize={20}
        maxSize={40}
        onCollapse={() => setIsLeftPanelCollapsed(true)}
        onExpand={() => setIsLeftPanelCollapsed(false)}
        className={ 'bg-gray-100 hidden xs:block ' + (isLeftPanelCollapsed ? "xs:block" : "")}
      >
        <div className="h-full mt-[20%] p-4">
          {!isLeftPanelCollapsed && leftPanelContent}
        </div>
      </ResizablePanel>
      <ResizableHandle withHandle />
      <ResizablePanel defaultSize={75}>
        <div className="flex flex-col">
        <nav className="flex items-center justify-between bg-white p-4 shadow-md">
              <button className="text-gray-600 hover:text-gray-800" onClick={() => navigateTo(pages[0])}>
                <ArrowLeft size={24} />
              </button>
              <h1 className="text-xl font-bold text-center">
              <span role="img" aria-label="å¯çˆ±å¥³ç”Ÿè¡¨æƒ…">ğŸ‘§</span> copi 
              </h1>
              <div className="w-8"></div> {/* è¿™æ˜¯ä¸ºäº†ä¿æŒå¯¼èˆªæ çš„å¹³è¡¡ */}
            </nav>
          <div  className="overflow-y-auto p-4 space-y-4 bg-gray-100">
            
            <div className="flex flex-col justify-center items-left h-[70vh]">
              <div ref={chatContainerRef} className="w-full h-full overflow-y-auto text-sm">
                {messages.map((message, index) => (
                  <div key={index} className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'} mb-4`}>
                    <div className="flex flex-col ">
                      <div className={`p-3 rounded-lg ${message.role === 'user' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}>
                        {message.parts[0].text}
                      </div>
                      {message.role === 'model' && (
                        <div className="flex justify-between items-center mt-2 text-xs text-gray-500">
                          <div className="flex space-x-2">
                            <TooltipProvider>
                              <Tooltip>
                                <TooltipTrigger asChild>
                                  <button 
                                    className={`${playingAudio === message.parts[0].text ? 'animate-pulse-fast' : ''}`}
                                    onClick={() => tts(message.parts[0].text, index)}
                                  >
                                    <Volume2 size={16} />
                                  </button>
                                </TooltipTrigger>
                                <TooltipContent>
                                  <p>{playingAudio === message.parts[0].text ? 'æ­£åœ¨æ’­æ”¾' : 'æ’­æ”¾'}</p>
                                </TooltipContent>
                              </Tooltip>
                            </TooltipProvider>
                            <TooltipProvider>
                              <Tooltip>
                                <TooltipTrigger asChild>
                                  <button 
                                    onClick={() => handleCopy(message.parts[0].text)}
                                  >
                                    {copiedText === message.parts[0].text ? (
                                      <Check size={16} className="text-green-500" />
                                    ) : (
                                      <Copy size={16} />
                                    )}
                                  </button>
                                </TooltipTrigger>
                                <TooltipContent>
                                  <p>{copiedText === message.parts[0].text ? 'å·²å¤åˆ¶' : 'å¤åˆ¶'}</p>
                                </TooltipContent>
                              </Tooltip>
                            </TooltipProvider>
                          </div>
                          <div className="flex flex-col space-y-1 text-right">
                            {message.requestTime !== undefined && (
                              <span>è¯·æ±‚: {message.requestTime / 1000}ç§’</span>
                            )}
                            {message.responseTime !== undefined && (
                              <span>å“åº”: {message.responseTime / 1000}ç§’</span>
                            )}
                            {message.audioRequestTime !== undefined && (
                              <span>éŸ³é¢‘è¯·æ±‚: {message.audioRequestTime / 1000}ç§’</span>
                            )}
                            {message.audioResponseTime !== undefined && (
                              <span>éŸ³é¢‘å“åº”: {message.audioResponseTime / 1000}ç§’</span>
                            )}
                          </div>
                        </div>
                      )}
                    </div>
                  </div>
                ))}
                {isWaitingAiChat  && (
                  <div className="flex justify-start mb-4">
                    <div className=" p-3 items-right rounded-lg bg-gray-200">
                      <div className="animate-pulse flex space-x-2">
                        <div className="w-2 h-2 bg-gray-400 rounded-full"></div>
                        <div className="w-2 h-2 bg-gray-400 rounded-full"></div>
                        <div className="w-2 h-2 bg-gray-400 rounded-full"></div>
                      </div>
                    </div>
                  </div>
                )}
              </div>
            </div>
          </div>


          <div className="flex justify-center items-center space-x-2 mx-4 mt-2">
            {words.map((word, index) => (
              <button
                key={index}
                className={`w-4 h-2 rounded-sm transition-all duration-1500 ease-in-out
                  ${word.hitCount && word.hitCount > 0 
                    ? 'bg-yellow-400  animate-[pulse_1s_ease-in-out]' 
                    : 'bg-gray-300'
                  }`}
                title={word.english}
              ></button>
            ))}
          </div>


          <div className="flex justify-end items-center space-x-2 mx-4 mt-2">
              <Switch
                id="text-to-speech"
                checked={textToSpeechEnabled}
                onCheckedChange={(checked) => {
                  setTextToSpeechEnabled(checked);
                  if (!checked) {
                    stopAudioPlayback();
                  }
                }}
              />
              <label htmlFor="text-to-speech" className="ml-2 text-sm">
                è‡ªåŠ¨å›å¤è¯­éŸ³
              </label>
              <Button
                variant="outline"
                size="sm"
                onClick={() => {
                  setMessages(messages.slice(0, 1));
                  setInput('');
                }}
                className="ml-auto "
              >
                æ¸…é™¤å¯¹è¯
              </Button>
            </div>

            
          <div className="p-2">
            <div className="flex items-center space-x-2 relative "> {/* æ·»åŠ  overflow-hidden */}
              <Button
                variant="outline"
                size="icon"
                onClick={() => setShowInput(!showInput)}
                className={`z-10 ${isRecording ? 'opacity-50 cursor-not-allowed' : ''}`}
                disabled={isRecording}
              >
                {showInput ? <Phone className="w-5 h-5" /> : <Keyboard className={`w-5 h-5`} />}
              </Button>
              <div className="flex-grow ">
                <div className={`flex transition-all duration-300 ease-in-out ${showInput ? 'translate-x-0 opacity-100' : '-translate-x-full opacity-0 pointer-events-none transition-opacity duration-500'}`}>
                  <Input
                    value={input}
                    onChange={(e:any) => setInput(e.target.value)}
                    placeholder="è¾“å…¥æ¶ˆæ¯..."
                    onKeyPress={(e:any) => e.key === 'Enter' && handleClickSend()}
                    className={`flex-grow   px-3 py-2 rounded-md bg-gray-200` }
                    />
                  {input && (
                    <Button onClick={handleClickSend} className="ml-2">
                      <Send className="w-5 h-5" />
                    </Button>
                  )}
                </div>
              </div>
              <div className={`absolute inset-y-0 left-10 right-0 transition-all duration-300 ease-in-out ${showInput ? 'translate-x-full' : 'translate-x-0'}`}>
              <Button
                variant={isListening ? "destructive" : "default"}
                className={`w-full h-full transition-all duration-300 ease-in-out text-white
                  ${showInput ? 'opacity-0 pointer-events-none' : 'opacity-100'}
                  ${isRecording 
                    ? 'shadow-inner transform scale-95 bg-red-500' 
                    : 'shadow-md'
                  }
                `}
                onClick={handleRecordSwitch}
              >
                <div className="relative w-full h-full overflow-hidden">
                  <div className={`absolute inset-0 flex items-center justify-center transition-transform duration-300 ${isRecording ? 'translate-y-full' : ''}`}>
                    æŒ‰ä½è¯´è¯ 
                  </div>
                  <div className={`absolute inset-0 flex items-center justify-center transition-transform duration-300 ${isRecording ? '' : '-translate-y-full'}`}>
                    <span className="flex items-center justify-center">
                      å¯¹è¯ä¸­
                      <span className="ml-1 flex">
                        <span className="animate-bounce-dot">.</span>
                        <span className="animate-bounce-dot animation-delay-200">.</span>
                        <span className="animate-bounce-dot animation-delay-400">.</span>
                      </span>
                    </span>
                  </div>
                </div>
              </Button>
              </div>
            </div>
          </div>
        </div>
      </ResizablePanel>

      {isCallActive && (
        <div className="absolute inset-0 bg-gray-500 bg-opacity-50 flex flex-col items-center justify-center">
          <div className="w-64 h-32 bg-white rounded-lg flex items-center justify-center">
            <svg width="200" height="60" viewBox="0 0 200 60">
              <path
                d={`M 0 30 Q 50 ${30 - audioLevel * 20} 100 30 Q 150 ${30 + audioLevel * 20} 200 30`}
                fill="none"
                stroke="blue"
                strokeWidth="2"
              />
            </svg>
          </div>
          <Button
            variant="destructive"
            size="lg"
            className="mt-4"  
            onClick={handleCallEnd}
          >
            <PhoneOff />
          </Button>
        </div>
      )}
    </ResizablePanelGroup>
  );
};

export default TodayDialogComponent;