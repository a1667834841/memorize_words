import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Button } from './ui/button';
import { Input } from './ui/input';
import { Phone, Send, Volume2, Copy, Check, PhoneOff, ArrowLeft, Keyboard } from 'lucide-react';
import { ResizableHandle, ResizablePanel, ResizablePanelGroup } from "./ui/resizable";
import { isMobileDevice } from '@/hooks/use-media-query';
import { Word } from '@/lib/types/words';
import { globalCache, Page,pages } from './app-router';
import { Switch } from './ui/switch'
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from "./ui/tooltip";
import {  AudioPlayer, audioToWav,  MicrophoneSoundDetector } from '@/app/utils/audio';
import { ResultReason, SpeechSynthesizer } from 'microsoft-cognitiveservices-speech-sdk';
import * as speechsdk from 'microsoft-cognitiveservices-speech-sdk';
import { getSpeechToken } from '@/hooks/use-websocket';


let globalRecognizer: speechsdk.SpeechRecognizer | null = null;
let globalSpeechSynthesizer: speechsdk.SpeechSynthesizer | null = null;
let tokenExpirationTime: number = 0;


interface Message {
  role: string;
  parts: Part[];
  requestTime?: number;
  responseTime?: number;
  audioRequestTime?: number;
  audioResponseTime?: number;
}
interface Part {
  text: string;
  words?: string[];
}

interface TodayDialogProps {
  navigateTo: (page: Page) => void;
}

const TodayDialogComponent: React.FC<TodayDialogProps> = ({ navigateTo }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const chatContainerRef = useRef<HTMLDivElement>(null);

  const [isLeftPanelCollapsed, setIsLeftPanelCollapsed] = useState(isMobileDevice());
  const [words, setWords] = useState<Word[]>([])
  const [currentAiMessage, setCurrentAiMessage] = useState('');
  const [textToSpeechEnabled, setTextToSpeechEnabled] = useState(true);
  const [isWaiting, setIsWaiting] = useState(false);
  const [audioCache, setAudioCache] = useState<{[key: string]: string}>({});
  const [playingAudio, setPlayingAudio] = useState<string | null>(null);
  const [copiedText, setCopiedText] = useState<string | null>(null);
  const [currentMessageIndex, setCurrentMessageIndex] = useState<number | null>(null);
  const [requestTime, setRequestTime] = useState(0);
  const [isAudioPlaying, setIsAudioPlaying] = useState(false);
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null);
  const [sourceNode, setSourceNode] = useState<AudioBufferSourceNode | null>(null);
  const [isCallActive, setIsCallActive] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [shouldSend, setShouldSend] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [showInput, setShowInput] = useState(false);
  const [isTransitioning, setIsTransitioning] = useState(false);
  

  const isMounted = useRef(true);
  const recognitionTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  useEffect(() => {
    return () => {
      isMounted.current = false;
      
    };
  }, []);

  
  // åœ¨ç»„ä»¶å¸è½½æ—¶æ¸…é™¤è¶…æ—¶
  useEffect(() => {
    return () => {
      if (recognitionTimeoutRef.current) {
        clearTimeout(recognitionTimeoutRef.current);
      }
    };
  }, []);

  useEffect(() => {
    // ç»„ä»¶æŒ‚è½½æ—¶çš„é€»è¾‘ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰

    // è¿”å›ä¸€ä¸ªæ¸…ç†å‡½æ•°ï¼Œå®ƒä¼šåœ¨ç»„ä»¶å¸è½½æ—¶æ‰§è¡Œ
    return () => {
      if (globalRecognizer) {
        console.log('Closing speech recognizer...');
        globalRecognizer.close();
        globalRecognizer = null;
      }
      if (globalSpeechSynthesizer) {
        console.log('Closing speech synthesizer...');
        globalSpeechSynthesizer.close();
        globalSpeechSynthesizer = null;
      }
    };
  }, []); // ç©ºä¾èµ–æ•°ç»„æ„å‘³ç€è¿™ä¸ªæ•ˆæœåªåœ¨ç»„ä»¶æŒ‚è½½å’Œå¸è½½æ—¶è¿è¡Œ


  // åœ¨æ¶ˆæ¯æ›´æ–°æ—¶æ»šåŠ¨åˆ°é¡¶éƒ¨
  useEffect(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight  ;
    }
  }, [messages]); // å‡è®¾ messages æ˜¯å­˜å‚¨å¯¹è¯æ¶ˆæ¯çš„çŠ¶æ€

  useEffect(() => {
    if (shouldSend && input) {
      handleSend();
      setShouldSend(false);  // é‡ç½®æ ‡å¿—
    }
  }, [shouldSend, input]);

  useEffect(() => {
    
    fetch('/api/daily-words')
    .then(response => response.json())
    .then((data: Word[]) => {
      setWords(data);
      setMessages([{ 
        role: 'model', 
        parts: [{ 
          text: `ä½ å¥½å‘€ï¼æˆ‘æ˜¯ä½ çš„ä»Šå¤©çš„è‹±è¯­è€å¸ˆï¼ä»Šå¤©å’±ä»¬å­¦äº†ä»¥ä¸‹å•è¯ï¼Œæœ‰12ä¸ªå•è¯è¯¶ï¼é‚£ä½ æƒ³ä»å“ªä¸ªå•è¯å¼€å§‹èŠèµ·å‘¢ï¼Ÿ`
        }] 
      }]);
    })
    .catch(error => {
      console.error('è·å–å•è¯æ—¶å‡ºé”™:', error)
    })
  }, []);

  useEffect(() => {

    // å½“å¯¹è¯ä¸­çš„modelçš„messageçš„textä¸­åŒ…å«wordsä¸­çš„ä¸€ä¸ªï¼Œåˆ™å°†å•è¯çš„hitCount+1
    messages.forEach(message => {
      if (message.role === 'model') {
        words.forEach(word => {
          if (message.parts[0].text.includes(word.english)) {
            setWords(prevWords => prevWords.map(w => w.english === word.english ? { ...w, hitCount: (w.hitCount || 0) + 1 } : w));
          }
        });
      }
    });
  }, [messages]);

  useEffect(() => {
    if (messages.length > 1 && isWaiting ) {
      messageSend(messages);
    }
  }, [isWaiting]);

  useEffect(() => {
    setIsLeftPanelCollapsed(isMobileDevice());
  }, []);

  useEffect(() => {
    const isStop = currentAiMessage.includes('@stop@')

    if (currentAiMessage) {
        setMessages(prevMessages => {
          const lastMessage = prevMessages[prevMessages.length - 1];
          if (lastMessage.role === 'user') {
              return [...prevMessages, { role: 'model', parts: [{ text: currentAiMessage.replace('@stop@', '') }],requestTime }];
          } else if (lastMessage.role === 'model' && lastMessage.parts[0].text !== currentAiMessage) {
              return [...prevMessages.slice(0, -1), { role: 'model', parts: [{ text: currentAiMessage.replace('@stop@', '') }] ,requestTime}];
          } else {
              return prevMessages;
          }
      });
    }
  
    if (!textToSpeechEnabled) {
      stopAudioPlayback();
    }

    if (isStop) {
      setIsWaiting(false);
    }
  }, [currentAiMessage, textToSpeechEnabled]);


  // æ–°å¢ï¼šåˆå§‹åŒ– recognizer çš„å‡½æ•°
  function initializeRecognizer(token: string, region: string): speechsdk.SpeechRecognizer {
    const speechConfig = speechsdk.SpeechConfig.fromAuthorizationToken(token, region);
    speechConfig.speechRecognitionLanguage = 'zh-CN';
    
    const audioConfig = speechsdk.AudioConfig.fromDefaultMicrophoneInput();
    return new speechsdk.SpeechRecognizer(speechConfig, audioConfig);
  }

  // æ–°å¢ä¸€ä¸ªÂ· speechSynthesizer å‡½æ•°
  function initializeSpeechSynthesizer(token: string, region: string): speechsdk.SpeechSynthesizer {
    const speechConfig = speechsdk.SpeechConfig.fromAuthorizationToken(token, region);
    // zh-CN-XiaoyuMultilingualNeural
    // zh-CN-XiaoxiaoMultilingualNeural
    speechConfig.speechSynthesisVoiceName = 'zh-CN-XiaochenMultilingualNeural'
    const audioConfig = speechsdk.AudioConfig.fromDefaultSpeakerOutput();
    

    return new SpeechSynthesizer(speechConfig, audioConfig);
  }


  async function refreshTokenIfNeeded() {
    const currentTime = Date.now();
    if (currentTime >= tokenExpirationTime) {
      const speechToken = await getSpeechToken();
      if (speechToken?.token && speechToken?.region) {
        if (globalRecognizer) {
          globalRecognizer.authorizationToken = speechToken.token;
        }
        // è®¾ç½®æ–°çš„è¿‡æœŸæ—¶é—´ï¼ˆ9åˆ†é’Ÿåï¼Œç•™å‡ºä¸€åˆ†é’Ÿçš„ç¼“å†²æ—¶é—´ï¼‰
        tokenExpirationTime = currentTime + 9 * 60 * 1000;
        return { token: speechToken.token, region: speechToken.region };
      } else {
        throw new Error('æ— æ³•è·å–æ–°çš„è¯­éŸ³ä»¤ç‰Œ');
      }
    }
    return null; // ä»¤ç‰Œä»ç„¶æœ‰æ•ˆ
  }

  async function tts (message :string,messageIndex:number) {

    if (!textToSpeechEnabled) {
      return
    }

    const emojiRegex = /[\uD800-\uDBFF][\uDC00-\uDFFF]|[\u2600-\u27BF]|[\uE000-\uF8FF]|\uD83C[\uDC00-\uDFFF]|\uD83D[\uDC00-\uDFFF]|[\u2700-\u27BF]/g;
    const realMessage = message.replace(emojiRegex,"")
    const refreshedToken = await refreshTokenIfNeeded();
    if (refreshedToken) {
      if (globalSpeechSynthesizer) {
        globalSpeechSynthesizer.close();
      }
      globalSpeechSynthesizer = initializeSpeechSynthesizer(refreshedToken.token, refreshedToken.region)
    } else if (!globalSpeechSynthesizer) {
      // å¦‚æœrecognizerä¸å­˜åœ¨ï¼Œä½¿ç”¨å½“å‰ä»¤ç‰Œåˆå§‹åŒ–
      const speechToken = await getSpeechToken();
      if (speechToken?.token && speechToken?.region) {
        globalSpeechSynthesizer = initializeSpeechSynthesizer(speechToken.token, speechToken.region);
        tokenExpirationTime = Date.now() + 9 * 60 * 1000;
      } else {
        throw new Error('æ— æ³•è·å–è¯­éŸ³ä»¤ç‰Œ');
      }
    }

    globalSpeechSynthesizer.speakTextAsync(realMessage,
      result => {
        if (result) {
          if (result.reason === ResultReason.SynthesizingAudioCompleted) {
            console.log('SynthesizingAudioCompleted')
          } else if (result.reason === ResultReason.Canceled) {
            console.error(`Speech synthesis canceled: ${result.errorDetails}`);
          }
          globalSpeechSynthesizer?.close();
          globalSpeechSynthesizer = null;
            
          setCurrentMessageIndex(messageIndex);
          // ä¿å­˜éŸ³é¢‘cache
          setAudioCache(prev => ({ ...prev, [realMessage]: URL.createObjectURL(new Blob([result.audioData], { type: 'audio/mpeg' })) }));
      }
      },error => {
        console.log(error);
        globalSpeechSynthesizer?.close();
      }
    )
   
  }

  async function sttFromMic() {
    try {
      const refreshedToken = await refreshTokenIfNeeded();
      
      if (refreshedToken) {
        // å¦‚æœä»¤ç‰Œè¢«åˆ·æ–°ï¼Œé‡æ–°åˆå§‹åŒ–recognizer
        if (globalRecognizer) {
          globalRecognizer.close();
        }
        globalRecognizer = initializeRecognizer(refreshedToken.token, refreshedToken.region);
      } else if (!globalRecognizer) {
        // å¦‚æœrecognizerä¸å­˜åœ¨ï¼Œä½¿ç”¨å½“å‰ä»¤ç‰Œåˆå§‹åŒ–
        const speechToken = await getSpeechToken();
        if (speechToken?.token && speechToken?.region) {
          globalRecognizer = initializeRecognizer(speechToken.token, speechToken.region);
          tokenExpirationTime = Date.now() + 9 * 60 * 1000;
        } else {
          throw new Error('æ— æ³•è·å–è¯­éŸ³ä»¤ç‰Œ');
        }
      }

      if (globalRecognizer) {
        setupRecognizerCallbacks();

        if (!isListening) {
          globalRecognizer.startContinuousRecognitionAsync();
          setIsListening(true);
        } else {
          globalRecognizer.stopContinuousRecognitionAsync();
          setIsListening(false);
        }
      }
    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«æ—¶å‡ºé”™:', error);
      setIsListening(false);
    }
  }


  
  function setupRecognizerCallbacks() {
    if (globalRecognizer) {
      globalRecognizer.recognizing = (s, e) => {
        // console.log(`recognizing text=`, e.result.text);
        // æ·»åŠ messagesæœ€åä¸€æ¡æ¶ˆæ¯
        
      };

      globalRecognizer.recognized = (s, e) => {
        // ç«‹å³æ›´æ–°è¾“å…¥
        setInput(e.result.text);
        setShouldSend(true)


        // è®¾ç½®æ–°çš„è¶…æ—¶
        // recognitionTimeoutRef.current = setTimeout(() => {
        //   setShouldSend(true);
        // }, 3000);
      };

      globalRecognizer.canceled = (s, e) => {
        console.log(`canceled reason=${e.reason}`);
        if (e.reason == speechsdk.CancellationReason.Error) {
          console.log(`"CANCELED: ErrorCode=${e.errorCode}`);
          console.log(`"CANCELED: ErrorDetails=${e.errorDetails}`);
          console.log("CANCELED: Did you set the speech resource key and region values?");
        }
        setIsListening(false);
      };

      globalRecognizer.sessionStopped = (s, e) => {
        console.log("Session stopped event");
        setIsListening(false);
        globalRecognizer?.stopContinuousRecognitionAsync()
      };
    }
  }


  const messageSend = async (messages: Message[]) => {
  
      const startTime = Date.now();

      const learnSituations = words.map(word => {
        return {
          word: word.english,
          mentionedTimes: word.hitCount
        }
      })

      // clone messages
      let realMessages = JSON.parse(JSON.stringify(messages))
      // å°†ç¬¬ä¸€æ¡çš„messageçš„textæ·»åŠ ä¸ŠlearnSituations
      realMessages[0].parts[0].text += `ä»Šå¤©å’±ä»¬å­¦äº†ä»¥ä¸‹å•è¯ï¼Œæœ‰12ä¸ªå•è¯ï¼é‚£ä½ æƒ³ä»å“ªä¸ªå•è¯å¼€å§‹èŠèµ·å‘¢ï¼ŸlearnSituations:`+JSON.stringify(learnSituations)

      try {
        const response = await fetch('/api/openai-chat', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ messages: realMessages }),
        });

        const endRequestTime = Date.now();
        setRequestTime(endRequestTime - startTime);

        if (!response.ok) {
          throw new Error('API è¯·æ±‚å¤±è´¥');
        }

        const reader = response.body?.getReader();
        const decoder = new TextDecoder();
        let fullMessage = '';
        let isDataReceived = false;

        // æ¥æ”¶æ•°æ®
        try {
          while (true) {
            const { done, value } = await reader?.read() ?? { done: true, value: undefined };
            if (done) {
              isDataReceived = true;
              break;
            }
            fullMessage += decoder.decode(value, { stream: true });
          }
        } catch (error) {
          console.error('æ¥æ”¶æ¶ˆæ¯æ—¶å‡ºé”™:', error);
          setCurrentAiMessage('æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚');
          setIsWaiting(false);
          return;
        }

        // å®ç°æ‰“å­—æœºæ•ˆæœ
        if (isDataReceived) {
          // å¼€å§‹æ’­æ”¾éŸ³é¢‘
          tts(fullMessage, messages.length - 1)
          for (let i = 0; i < fullMessage.length; i++) {
            setCurrentAiMessage(prev => prev + fullMessage[i]);
            // æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡ç‚¹ç¬¦å·
            if (['ï¼Œ', 'ã€‚', 'ï¼Ÿ', 'ï¼'].includes(fullMessage[i])) {
              await new Promise(resolve => setTimeout(resolve, 150));
            } else {
              await new Promise(resolve => setTimeout(resolve, 50));
            }
          }
          setCurrentAiMessage(prev => prev + '@stop@');
        }

        setIsWaiting(false);
      }
     catch (error) {
      console.error('å‘é€æ¶ˆæ¯æ—¶å‡ºé”™:', error);
      setCurrentAiMessage('æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚');
    }
  }

  const handleSend = async () => {
    if (input && input.trim()) {
      const newUserMessage = { role: 'user', parts: [{ text: input }] };
      setInput('');
      setCurrentAiMessage('');
      setIsWaiting(true);
      setMessages(prevMessages => [...prevMessages, newUserMessage]);
     
    }
  };



  const handleCopy = (text: string) => {
    navigator.clipboard.writeText(text).then(() => {
      setCopiedText(text);
      setTimeout(() => setCopiedText(null), 1000);
    });
  };

  const leftPanelContent = (
    <div className="h-auto p-4 bg-gray-100">
      <h2 className="text-lg font-bold mb-4">ä»Šæ—¥å•è¯</h2>
      {!isLeftPanelCollapsed && words.map((word, index) => (
        <div key={index} className="mb-2 sm:text-sm text-xs">
          <span className="font-bold text-gray-800">{word.english}</span> - <span className="text-gray-600">{word.chinese}</span>
        </div>
      ))}
    </div>
  );

  const scrollToBottom = useCallback(() => {
    if (chatContainerRef.current) {
      chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight;
    }
  }, []);

  useEffect(() => {
    scrollToBottom();
    
    const chatContainer = chatContainerRef.current;
    if (chatContainer) {
      const observer = new MutationObserver(scrollToBottom);
      observer.observe(chatContainer, { childList: true, subtree: true });
      
      return () => observer.disconnect();
    }
  }, [scrollToBottom]);

  const stopAudioPlayback = () => {
    if (sourceNode) {
      sourceNode.stop();
      setSourceNode(null);
    }
    if (audioContext) {
      audioContext.close();
      setAudioContext(null);
    }
    setPlayingAudio(null);
    setCurrentMessageIndex(null);
  };



  const startRecording = async () => {
    // setIsCallActive(true);
    sttFromMic()
  };

  const stopRecording = () => {
    setIsCallActive(false);
    
    globalRecognizer?.stopContinuousRecognitionAsync();
  };



  const handleCallStart = () => {
    startRecording();
  };

  const handleCallEnd = () => {
    setIsRecording(false);
    stopRecording();
  };

  const handleRecordSwitch = () => {
    if (!isRecording) {
      setIsTransitioning(true);
      setIsRecording(true);
      // å‡è®¾è¿™æ˜¯å¼€å§‹å½•éŸ³çš„å‡½æ•°
      startRecording().then(() => {
        setIsListening(true);
        setIsTransitioning(false);
      });
    } else {
      setIsListening(false);
      setIsRecording(false);
      // å‡è®¾è¿™æ˜¯åœæ­¢å½•éŸ³çš„å‡½æ•°
      stopRecording();
    }
  };

  const handleRecordEnd = () => {
    setIsRecording(!isRecording);
    stopRecording();
  };

  return (
    <ResizablePanelGroup direction="horizontal" className="relative">
      <ResizablePanel
        defaultSize={25}
        collapsible={isLeftPanelCollapsed}
        collapsedSize={5}
        minSize={20}
        maxSize={40}
        onCollapse={() => setIsLeftPanelCollapsed(true)}
        onExpand={() => setIsLeftPanelCollapsed(false)}
        className={ 'bg-gray-100 hidden xs:block ' + (isLeftPanelCollapsed ? "xs:block" : "")}
      >
        <div className="h-full mt-[20%] p-4">
          {!isLeftPanelCollapsed && leftPanelContent}
        </div>
      </ResizablePanel>
      <ResizableHandle withHandle />
      <ResizablePanel defaultSize={75}>
        <div className="flex flex-col">
        <nav className="flex items-center justify-between bg-white p-4 shadow-md">
              <button className="text-gray-600 hover:text-gray-800" onClick={() => navigateTo(pages[0])}>
                <ArrowLeft size={24} />
              </button>
              <h1 className="text-xl font-bold text-center">
              <span role="img" aria-label="å¯çˆ±å¥³ç”Ÿè¡¨æƒ…">ğŸ‘§</span> copi 
              </h1>
              <div className="w-8"></div> {/* è¿™æ˜¯ä¸ºäº†ä¿æŒå¯¼èˆªæ çš„å¹³è¡¡ */}
            </nav>
          <div  className="overflow-y-auto p-4 space-y-4 bg-gray-100">
            
            <div className="flex flex-col justify-center items-left h-[70vh]">
              <div ref={chatContainerRef} className="w-full h-full overflow-y-auto text-sm">
                {messages.map((message, index) => (
                  <div key={index} className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'} mb-4`}>
                    <div className="flex flex-col ">
                      <div className={`p-3 rounded-lg ${message.role === 'user' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}>
                        {message.parts[0].text}
                      </div>
                      {message.role === 'model' && (
                        <div className="flex justify-between items-center mt-2 text-xs text-gray-500">
                          <div className="flex space-x-2">
                            <TooltipProvider>
                              <Tooltip>
                                <TooltipTrigger asChild>
                                  <button 
                                    className={`${playingAudio === message.parts[0].text ? 'animate-pulse-fast' : ''}`}
                                    onClick={() => tts(message.parts[0].text, index)}
                                  >
                                    <Volume2 size={16} />
                                  </button>
                                </TooltipTrigger>
                                <TooltipContent>
                                  <p>{playingAudio === message.parts[0].text ? 'æ­£åœ¨æ’­æ”¾' : 'æ’­æ”¾'}</p>
                                </TooltipContent>
                              </Tooltip>
                            </TooltipProvider>
                            <TooltipProvider>
                              <Tooltip>
                                <TooltipTrigger asChild>
                                  <button 
                                    onClick={() => handleCopy(message.parts[0].text)}
                                  >
                                    {copiedText === message.parts[0].text ? (
                                      <Check size={16} className="text-green-500" />
                                    ) : (
                                      <Copy size={16} />
                                    )}
                                  </button>
                                </TooltipTrigger>
                                <TooltipContent>
                                  <p>{copiedText === message.parts[0].text ? 'å·²å¤åˆ¶' : 'å¤åˆ¶'}</p>
                                </TooltipContent>
                              </Tooltip>
                            </TooltipProvider>
                          </div>
                          <div className="flex flex-col space-y-1 text-right">
                            {message.requestTime !== undefined && (
                              <span>è¯·æ±‚: {message.requestTime / 1000}ç§’</span>
                            )}
                            {message.responseTime !== undefined && (
                              <span>å“åº”: {message.responseTime / 1000}ç§’</span>
                            )}
                            {message.audioRequestTime !== undefined && (
                              <span>éŸ³é¢‘è¯·æ±‚: {message.audioRequestTime / 1000}ç§’</span>
                            )}
                            {message.audioResponseTime !== undefined && (
                              <span>éŸ³é¢‘å“åº”: {message.audioResponseTime / 1000}ç§’</span>
                            )}
                          </div>
                        </div>
                      )}
                    </div>
                  </div>
                ))}
                {isWaiting && !currentAiMessage && (
                  <div className="flex justify-start mb-4">
                    <div className=" p-3 items-right rounded-lg bg-gray-200">
                      <div className="animate-pulse flex space-x-2">
                        <div className="w-2 h-2 bg-gray-400 rounded-full"></div>
                        <div className="w-2 h-2 bg-gray-400 rounded-full"></div>
                        <div className="w-2 h-2 bg-gray-400 rounded-full"></div>
                      </div>
                    </div>
                  </div>
                )}
              </div>
            </div>
          </div>


          <div className="flex justify-center items-center space-x-2 mx-4 mt-2">
            {words.map((word, index) => (
              <button
                key={index}
                className={`w-4 h-2 rounded-sm transition-all duration-1500 ease-in-out
                  ${word.hitCount && word.hitCount > 0 
                    ? 'bg-yellow-400  animate-[pulse_1s_ease-in-out]' 
                    : 'bg-gray-300'
                  }`}
                title={word.english}
              ></button>
            ))}
          </div>


          <div className="flex justify-end items-center space-x-2 mx-4 mt-2">
              <Switch
                id="text-to-speech"
                checked={textToSpeechEnabled}
                onCheckedChange={(checked) => {
                  setTextToSpeechEnabled(checked);
                  if (!checked) {
                    stopAudioPlayback();
                  }
                }}
              />
              <label htmlFor="text-to-speech" className="ml-2 text-sm">
                æ–‡å­—è½¬è¯­éŸ³
              </label>
              <Button
                variant="outline"
                size="sm"
                onClick={() => {
                  setMessages(messages.slice(0, 1));
                  setInput('');
                }}
                className="ml-auto "
              >
                æ¸…é™¤å¯¹è¯
              </Button>
            </div>

            
          <div className="p-2">
            <div className="flex items-center space-x-2 relative "> {/* æ·»åŠ  overflow-hidden */}
              <Button
                variant="outline"
                size="icon"
                onClick={() => setShowInput(!showInput)}
                className="z-10"
              >
                {showInput ? <Phone className="w-5 h-5" /> : <Keyboard className="w-5 h-5" />}
              </Button>
              <div className="flex-grow ">
                <div className={`flex transition-all duration-300 ease-in-out ${showInput ? 'translate-x-0 opacity-100' : '-translate-x-full opacity-0 pointer-events-none transition-opacity duration-500'}`}>
                  <Input
                    value={input}
                    onChange={(e:any) => setInput(e.target.value)}
                    placeholder="è¾“å…¥æ¶ˆæ¯..."
                    onKeyPress={(e:any) => e.key === 'Enter' && handleSend()}
                    className={`flex-grow   px-3 py-2 rounded-md bg-gray-200` }
                    />
                  {input && (
                    <Button onClick={handleSend} className="ml-2">
                      <Send className="w-5 h-5" />
                    </Button>
                  )}
                </div>
              </div>
              <div className={`absolute inset-y-0 left-10 right-0 transition-all duration-300 ease-in-out ${showInput ? 'translate-x-full' : 'translate-x-0'}`}>
                <Button
                  variant={isRecording && isListening ? "destructive" : "default"}
                  className={`w-full h-full transition-all duration-300 ease-in-out text-white
                    ${showInput ? 'opacity-0 pointer-events-none' : 'opacity-100'}
                    ${isRecording 
                      ? 'shadow-inner transform scale-95' 
                      : 'shadow-md'
                    }
                    ${isTransitioning ? 'animate-pulse' : ''}
                  `}
                  onClick={handleRecordSwitch}
                >
                  {isRecording ? (
                    <span className="flex items-center justify-center">
                      å¯¹è¯ä¸­
                      <span className="ml-1 flex">
                        <span className="animate-bounce-dot">.</span>
                        <span className="animate-bounce-dot animation-delay-200">.</span>
                        <span className="animate-bounce-dot animation-delay-400">.</span>
                      </span>
                    </span>
                  ) : 'æŒ‰ä½è¯´è¯'}
                </Button>
              </div>
            </div>
          </div>
        </div>
      </ResizablePanel>

      {isCallActive && (
        <div className="absolute inset-0 bg-gray-500 bg-opacity-50 flex flex-col items-center justify-center">
          <div className="w-64 h-32 bg-white rounded-lg flex items-center justify-center">
            <svg width="200" height="60" viewBox="0 0 200 60">
              <path
                d={`M 0 30 Q 50 ${30 - audioLevel * 20} 100 30 Q 150 ${30 + audioLevel * 20} 200 30`}
                fill="none"
                stroke="blue"
                strokeWidth="2"
              />
            </svg>
          </div>
          <Button
            variant="destructive"
            size="lg"
            className="mt-4"  
            onClick={handleCallEnd}
          >
            <PhoneOff />
          </Button>
        </div>
      )}
    </ResizablePanelGroup>
  );
};

export default TodayDialogComponent;